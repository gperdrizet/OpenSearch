{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU resource optimization\n",
    "\n",
    "We know from early experiments with pre-embedding texts for indexing into OpeSearch that increasing the embedding batch size does not have a net performance benefit.\n",
    "\n",
    "Now, the idea is to try embedding several small batches in parallel to see if we can get a speed-up that way.\n",
    "\n",
    "## 1. Run set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
